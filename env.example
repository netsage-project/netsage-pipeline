# Local RabbitMQ Server config
RABBITMQ_ERLANG_COOKIE='secret cookie'
RABBIT_HOST=rabbit
RABBITMQ_DEFAULT_USER=guest
RABBITMQ_DEFAULT_PASS=guest
discovery.type=single-node

# rabbitmq server for the importer output queue = the Logstash input queue 
# default is to use the local rabbitmq server
rabbitmq_input_host=rabbit
rabbitmq_input_username=guest
rabbitmq_input_pw=guest

# rabbitmq server for the Logstash output queue
# default is to use the local rabbitmq server
# === FOR NETSAGE, ASK FOR THE PROPER SETTINGS ===
rabbitmq_output_host=rabbit
rabbitmq_output_username=guest
rabbitmq_output_pw=guest
rabbitmq_output_key=netsage_archive_input

# To drop all flows except those using the specfied interfaces
# (see the Docker Advanced documentation)
  ifindex_filter_flag=False
# ifindex_filter_keep=111; Sensor 1: 456; Sensor 2: 789,123

# To change the sensor name for flows using a certain interface
# (See the Docker Advanced documentation)
  ifindex_sensor_rename_flag=False
# ifindex_sensor_rename_old_name=oldname
# ifindex_sensor_rename_new_name=newname
# ifindex_sensor_rename_ifindex=0

# To "manually" correct flow sizes and rates for sampling for specified sensors
# (See the Docker Advanced documentation. This is uncommon.)
  sampling_correction_flag=False
# sampling_correction_sensors=sensor1,sensor2
# sampling_correction_factor=1

# Logstash settings
# set this to false so we don't install elasticsearch locally 
XPACK_MONITORING_ENABLED=false
# java heap size for logstash
LS_JAVA_OPTS=-Xmx2g -Xms2g
# the logstash aggregation filter requires that only one logstash worker is running
PIPELINE_WORKERS=1
# for debugging
## LOG_LEVEL=debug

# Importer settings
# == EXAMPLE VALUES MUST BE REPLACED == 
sflowSensorName=The Sflow Sensor Name
netflowSensorName=The Netflow Sensor Name

# Logstash Aggregation Filter settings
# default inactivity_timeout is 630 sec for 5-minute nfcapd files; for 15-minute files, use 960 sec.
# max_flow_timeout is the maximum flow duration; longer flows will be broken up.
inactivity_timeout=630
max_flow_timeout=86400
aggregation_maps_path=/data/logstash-aggregation-maps

# In case you run elasticsearch and kibana
ELASTIC_HOSTNAME='elastic'
