# Sensor names that logstash will assign to flows
# == EXAMPLE VALUES MUST BE REPLACED == 
sflowSensorName=The Sflow Sensor Name
netflowSensorName=The Netflow Sensor Name

# Processed flows are normally written to a rabbit queue.
# The default is to write to the local rabbitmq server "rabbit".
# === TO SEND PROCESSED FLOWS TO GlobalNOC, ASK FOR THE PROPER SETTINGS ===
rabbitmq_output_host=rabbit
rabbitmq_output_username=guest
rabbitmq_output_pw=guest
rabbitmq_output_key=netsage_archive_input

# Logstash Aggregation Filter settings
# Default inactivity_timeout is 5-minute. If no matching flows have come in for 5 minutes, end the aggregated flow. 
# Default max_flow_timeout is 1 hour. This is the maximum allowed flow duration; longer flows will be broken up.
# Aggregation_maps_path is where flows undergoing aggregation are saved if logstash shuts down. Default is for Docker installs.
inactivity_timeout=300
max_flow_timeout=3600
aggregation_maps_path=/data/logstash-aggregation-maps

# PROCESSING OPTIONS - see the "Docker Advanced" documentation

# To do ifindex (interface) filtering of flows from specified sensors:
# Flows from listed sensors will be dropped unless src or dst interface is in the list of ifindexes to keep.
# "ALL" can refer to all sensors or all interfaces of a sensor.
# If a sensor is not referenced, all its flows will be kept.
ifindex_filter_flag=False
#ifindex_filter_keep= Sensor 1: 456,789; Sensor 2: ALL

# To change the sensor name for flows from a specified sensor and interface:
# Provide the ifindex, old and new sensor names.
ifindex_sensor_rename_flag=False
#ifindex_sensor_rename_ifindex=123
#ifindex_sensor_rename_old_name=old name
#ifindex_sensor_rename_new_name=new name

# To correct for sampling in the logstash pipeline:
# Normally, sampling corrections are applied before ingest into logstash, but in certain cases, 
# it may need to be done in logstash.
# List affected sensors and the correction factor.
sampling_correction_flag=False
#sampling_correction_sensors=sensor 1;sensor 2
#sampling_correction_factor=100

# To do subnet filtering of flows:
# Flows from specified sensors will be dropped unless src or dst is in the list of subnets to keep.
# "ALL" can refer to all sensors.
# If a sensor is not referenced, all its flows will be kept.
subnet_filter_flag=False
#subnet_filter_keep=Sensor 1: 123.45.6.0/16; Sensor 2: 123.33.33.0/24, 456.66.66.0/24

# To NOT deidentify flows:
# Deidentification of IP addresses is done by default.
# To keep full IP addresses, set this parameter to True.
full_IPs_flag=False

# OTHER SETTINGS

# Logstash settings
# set this to false so we don't install elasticsearch locally 
XPACK_MONITORING_ENABLED=false
# java heap size for logstash
LS_JAVA_OPTS=-Xmx2g -Xms2g
# Do not change - the logstash aggregation filter requires that only one logstash worker is running!
PIPELINE_WORKERS=1
# for debugging
## LOG_LEVEL=debug

# Local RabbitMQ Server config
RABBITMQ_ERLANG_COOKIE='secret cookie'
RABBIT_HOST=rabbit
RABBITMQ_DEFAULT_USER=guest
RABBITMQ_DEFAULT_PASS=guest
discovery.type=single-node

# Importer output rabbit host = Logstash input rabbit host
# default is to use the local rabbitmq server
rabbitmq_input_host=rabbit
rabbitmq_input_username=guest
rabbitmq_input_pw=guest

# In case you run elasticsearch and kibana
ELASTIC_HOSTNAME='elastic'
