# Sensor name to assign
# == EXAMPLE VALUES MUST BE REPLACED == 
sflowSensorName=The Sflow Sensor Name
netflowSensorName=The Netflow Sensor Name

# Final Logstash output is to a rabbit queue,
# the default is to write to the local rabbitmq server.
# === FOR SENDING PROCESSED FLOWS TO GlobalNOC, ASK FOR THE PROPER SETTINGS ===
rabbitmq_output_host=rabbit
rabbitmq_output_username=guest
rabbitmq_output_pw=guest
rabbitmq_output_key=netsage_archive_input

# To do ifindex (interface) filtering of flows from specified sensors:
# Flows will be dropped unless src or dst interface is in the list of ifindexes to keep.
# (see the Docker Advanced documentation)
# "ALL" can refer to all sensors or all interfaces of a sensor.
# If a sensor is not referenced, all flows will be kept.
ifindex_filter_flag=False
#example: ifindex_filter_keep= Sensor-1: 456,789; Sensor 2: ALL

# To change the sensor name for flows from a given sensor and using a certain interface:
# (See the Docker Advanced documentation)
ifindex_sensor_rename_flag=False
#example: ifindex_sensor_rename_ifindex=123
#example: ifindex_sensor_rename_old_name=old name
#example: ifindex_sensor_rename_new_name=new name

# To account for sampling in the logstash pipeline, list affected sensors and the correction factor.
# Normally, corrections are applied before ingest into logstash, but in certain cases, this may be required.
# (See the Docker Advanced documentation)
sampling_correction_flag=False
#example: sampling_correction_sensors=sensor 1;sensor 2
#example: sampling_correction_factor=100

# To do subnet filtering of flows from specified sensors:
# Flows will be dropped unless src or dst is in the list of subnets to keep.
# (see the Docker Advanced documentation)
# "ALL" can refer to all sensors
# If a sensor is not referenced, all its flows will be kept.
subnet_filter_flag=False
#example: subnet_filter_keep=Sensor 1: 123.45.6.0/16; Sensor 2: 123.33.33.0/24, 456.66.66.0/24

# Logstash Aggregation Filter settings
# default inactivity_timeout is 5-minute 
# default max_flow_timeout is 1 hour. This is the maximum allowed flow duration; longer flows will be broken up.
inactivity_timeout=300
max_flow_timeout=3600
aggregation_maps_path=/data/logstash-aggregation-maps

# Logstash settings
# set this to false so we don't install elasticsearch locally 
XPACK_MONITORING_ENABLED=false
# java heap size for logstash
LS_JAVA_OPTS=-Xmx2g -Xms2g
# the logstash aggregation filter requires that only one logstash worker is running
PIPELINE_WORKERS=1
# for debugging
## LOG_LEVEL=debug

# Local RabbitMQ Server config
RABBITMQ_ERLANG_COOKIE='secret cookie'
RABBIT_HOST=rabbit
RABBITMQ_DEFAULT_USER=guest
RABBITMQ_DEFAULT_PASS=guest
discovery.type=single-node

# Importer output rabbit host = Logstash input rabbit host
# default is to use the local rabbitmq server
rabbitmq_input_host=rabbit
rabbitmq_input_username=guest
rabbitmq_input_pw=guest

# In case you run elasticsearch and kibana
ELASTIC_HOSTNAME='elastic'
