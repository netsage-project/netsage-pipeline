# Importer settings
# == EXAMPLE VALUES MUST BE REPLACED == 
sflowSensorName=The Sflow Sensor Name
netflowSensorName=The Netflow Sensor Name

# Logstash output rabbit queue
# default is to use the local rabbitmq server
# === FOR SENDING TO TACC, ASK FOR THE PROPER SETTINGS ===
rabbitmq_output_host=
rabbitmq_output_username=
rabbitmq_output_pw=
rabbitmq_output_key=

# To include or exclude all flows except those using the specfied interfaces.
# Options are Include, Exclude, or False
# (see the Docker Advanced documentation)
ifindex_filter_flag=False
# ifindex_filter_list=111;Sensor 1:456;Sensor 2:789,123

# To include or exclude all flows except those using the specfied subnets
# Options are Include, Exclude, or False
# (see the Docker Advanced documentation)
subnet_filter_flag=False
# subnet_filter_list=Sensor A Name:123.45.6.0/16;Sensor B Name:123.33.33.0/24,456.66.66.0/24

# To change the sensor name for flows using a certain interface
# (See the Docker Advanced documentation)
ifindex_sensor_rename_flag=False
# ifindex_sensor_rename_old_name=oldname
# ifindex_sensor_rename_new_name=newname
# ifindex_sensor_rename_ifindex=0

# To "manually" correct flow sizes and rates for sampling for specified sensors
# (See the Docker Advanced documentation. This is uncommon.)
sampling_correction_flag=False
# sampling_correction_sensors=sensor1,sensor2
# sampling_correction_factor=1

# Logstash Aggregation Filter settings
# default inactivity_timeout is 630 sec for 5-minute nfcapd files; for 15-minute files, use 960 sec.
# max_flow_timeout is the maximum flow duration; longer flows will be broken up.
inactivity_timeout=630
max_flow_timeout=86400
aggregation_maps_path=/data/logstash-aggregation-maps

# throw out flows shorter than this number seconds
DURATION_THRESHOLD=0.1

# Logstash settings
# set this to false so we don't install elasticsearch locally 
XPACK_MONITORING_ENABLED=false
# java heap size for logstash
LS_JAVA_OPTS=-Xmx4g -Xms4g
# the logstash aggregation filter requires that only one logstash worker is running
PIPELINE_WORKERS=1
# for debugging
## LOG_LEVEL=debug

# Local RabbitMQ Server config
RABBITMQ_ERLANG_COOKIE='secret cookie'
RABBIT_HOST=rabbit
RABBITMQ_DEFAULT_USER=guest
RABBITMQ_DEFAULT_PASS=guest
discovery.type=single-node

# Importer output rabbit host = Logstash input rabbit host
# default is to use the local rabbitmq server
rabbitmq_input_host=rabbit
rabbitmq_input_username=guest
rabbitmq_input_pw=guest

# In case you run elasticsearch and kibana
ELASTIC_HOSTNAME='elastic'
