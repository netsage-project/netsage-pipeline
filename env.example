# IMPORTER SETTINGS
# === EXAMPLE VALUES MUST BE REPLACED === 
sflowSensorName=The Sflow Sensor Name
netflowSensorName=The Netflow Sensor Name

# LOGSTASH PIPELINE SETTINGS
# output rabbit queue - default is to write to the local rabbitmq server
# === FOR SENDING TO GlobalNOC, ASK FOR THE PROPER SETTINGS ===
rabbitmq_output_host=rabbit
rabbitmq_output_username=guest
rabbitmq_output_pw=guest
rabbitmq_output_key=netsage_archive_input

# LOGSTASH PIPELINE - ADVANCED OPTIONS

# To drop all flows except those using the specfied interfaces
# (see the Docker Advanced documentation)
ifindex_filter_flag=False
# ifindex_filter_keep=111; ALL: 222; Sensor 1: 456; Sensor 2: 789,123

# To drop all flows except those using the specfied subnets
# (see the Docker Advanced documentation)
subnet_filter_flag=False
# subnet_filter_keep=ALL: 123.456.0.0/16; Sensor 2: 987.654.1.0/24, 987.654.2.0/24

# To change the sensor name for flows using a certain interface
# (See the Docker Advanced documentation)
ifindex_sensor_rename_flag=False
# ifindex_sensor_rename_old_name=oldname
# ifindex_sensor_rename_new_name=newname
# ifindex_sensor_rename_ifindex=0

# To "manually" correct flow sizes and rates for sampling for specified sensors
# (See the Docker Advanced documentation. This is uncommon.)
sampling_correction_flag=False
# sampling_correction_sensors=sensor1,sensor2
# sampling_correction_factor=100

# To skip deidentification of src and dst IPs, i.e., 
# to save and show full IPs, set this flag to False. Default is True.
deidentification_flag = True

# Logstash Aggregation Filter settings
# The default inactivity_timeout is 630 sec for 5-minute nfcapd files; for 15-minute files, use 960 sec.
# Max_flow_timeout is the maximum flow duration; longer flows will be broken up.
inactivity_timeout=630
max_flow_timeout=86400
aggregation_maps_path=/data/logstash-aggregation-maps

# MORE LOGSTASH SETTINGS 
# input rabbit host - use the local rabbitmq server
rabbitmq_input_host=rabbit
rabbitmq_input_username=guest
rabbitmq_input_pw=guest
# the logstash aggregation filter only works if there is a single logstash worker 
PIPELINE_WORKERS=1
# set this to false so we don't install elasticsearch locally 
XPACK_MONITORING_ENABLED=false
# java heap size for logstash
LS_JAVA_OPTS=-Xmx2g -Xms2g
# for debugging
## LOG_LEVEL=debug

# LOCAL RABBITMQ SERVER SETTINGS
RABBITMQ_ERLANG_COOKIE='secret cookie'
RABBIT_HOST=rabbit
RABBITMQ_DEFAULT_USER=guest
RABBITMQ_DEFAULT_PASS=guest
discovery.type=single-node

# In case you run elasticsearch and kibana
ELASTIC_HOSTNAME='elastic'
