filter {
  if [type] == "flow" {

    mutate {
# remove unneeded fields
     remove_field =>  "[meta][src_city]"
     remove_field =>  "[meta][dst_city]"
     remove_field =>  "[values][src_asn]"
     remove_field =>  "[values][dst_asn]"
    }

# convert strings to numeric logstash data types 
    mutate {
     convert => {
      "[values][duration]"    => "float"
      "[values][num_bits]"    => "integer"
      "[values][bits_per_second]"    => "float"
      "[values][packets_per_second]" => "integer"
      "[values][num_packets]" => "integer"
      "[meta][src_asn]"       => "integer"
      "[meta][dst_asn]"       => "integer"
      "[meta][src_port]"      => "integer"
      "[meta][dst_port]"      => "integer"
      "[meta][src_latitude]"  => "float"
      "[meta][dst_latitude]"  => "float"
      "[meta][src_longitude]" => "float"
      "[meta][dst_longitude]" => "float"
      "[start]"               => "float"
      "[end]"                 => "float"
      }
    }

# save original timestamps
    mutate {
      add_field => { "start_timestamp" => "%{start}" }
      add_field => { "end_timestamp" => "%{end}" }
    }

# Convert any millisecond timestamps to seconds
    ruby {
      code => " xstart = event.get('start')
                xend = event.get('end')
                event.set('start', xstart/1000) if xstart > 9999999999
                event.set('end', xend/1000)     if xend  >  9999999999
              "
    }

# Convert start and end timestamps to month-day-year-time dates
# UNIX pattern - will parse float or int value for unix time in seconds since epoch
    date {
      match => [ "start","UNIX" ]
      target => "start"
    }
    date {
      match => [ "end","UNIX" ]
      target => "end"
    }

  }
}
