(window.webpackJsonp=window.webpackJsonp||[]).push([[98],{168:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return s})),n.d(t,"metadata",(function(){return r})),n.d(t,"toc",(function(){return l})),n.d(t,"default",(function(){return d}));var a=n(3),i=n(7),o=(n(0),n(209)),s={id:"logstash",title:"Logstash Pipeline",sidebar_label:"Logstash"},r={unversionedId:"pipeline/logstash",id:"pipeline/logstash",isDocsHomePage:!1,title:"Logstash Pipeline",description:"The Logstash portion of the Netsage Pipeline reads flows from a RabbitMQ queue, performs various transformations and adds additional information, then sends them to a rabbitMQ queue on a different host. Eventually the data ends up in an Elasticsearch data store.",source:"@site/docs/pipeline/logstash.md",slug:"/pipeline/logstash",permalink:"/netsage-pipeline/docs/next/pipeline/logstash",editUrl:"https://github.com/netsage-project/netsage-pipeline/edit/master/website/docs/pipeline/logstash.md",version:"current",sidebar_label:"Logstash",sidebar:"Pipeline",previous:{title:"Pmacct",permalink:"/netsage-pipeline/docs/next/pipeline/pmacct"},next:{title:"Elasticsearch",permalink:"/netsage-pipeline/docs/next/pipeline/elastic"}},l=[{value:"Logstash Sequence",id:"logstash-sequence",children:[{value:"01-input-rabbit.conf",id:"01-input-rabbitconf",children:[]},{value:"05-translate-pmacct.conf",id:"05-translate-pmacctconf",children:[]},{value:"10-preliminaries.conf",id:"10-preliminariesconf",children:[]},{value:"15-sensor-specific-changes.conf",id:"15-sensor-specific-changesconf",children:[]},{value:"20-add_id.conf",id:"20-add_idconf",children:[]},{value:"40-aggregation.conf",id:"40-aggregationconf",children:[]},{value:"41-thresholds.conf",id:"41-thresholdsconf",children:[]},{value:"45-geoip-tagging.conf",id:"45-geoip-taggingconf",children:[]},{value:"50-asn.conf",id:"50-asnconf",children:[]},{value:"53-caida-org.conf",id:"53-caida-orgconf",children:[]},{value:"55-member-orgs.conf",id:"55-member-orgsconf",children:[]},{value:"60-scireg-tagging-fakegeoip.conf",id:"60-scireg-tagging-fakegeoipconf",children:[]},{value:"70-deidentify.conf",id:"70-deidentifyconf",children:[]},{value:"80-privatize.org.conf",id:"80-privatizeorgconf",children:[]},{value:"88-preferred-location-org.conf",id:"88-preferred-location-orgconf",children:[]},{value:"90-additional-fields.conf",id:"90-additional-fieldsconf",children:[]},{value:"95-cleanup.conf",id:"95-cleanupconf",children:[]},{value:"98-post-process.conf",id:"98-post-processconf",children:[]},{value:"99-output-rabbit.conf",id:"99-output-rabbitconf",children:[]},{value:"Final Stage",id:"final-stage",children:[]}]},{value:"Field names",id:"field-names",children:[]}],c={toc:l};function d(e){var t=e.components,n=Object(i.a)(e,["components"]);return Object(o.b)("wrapper",Object(a.a)({},c,n,{components:t,mdxType:"MDXLayout"}),Object(o.b)("p",null,"The Logstash portion of the Netsage Pipeline reads flows from a RabbitMQ queue, performs various transformations and adds additional information, then sends them to a rabbitMQ queue on a different host. Eventually the data ends up in an Elasticsearch data store."),Object(o.b)("p",null,'Logstash .conf files invoke various "filters" and actions. In the bare metal installation, these conf files are located in /etc/logstash/conf.d/. In a docker installation, they are located in the conf-logstash/ directory of the git checkout of the pipeline. See below for a brief description of what each does and check the files for comments.'),Object(o.b)("blockquote",null,Object(o.b)("ul",{parentName:"blockquote"},Object(o.b)("li",{parentName:"ul"},"All ","*",".conf files in conf.d/ or conf-logstash/ are executed in alphabetical order, as if they were one huge file. Those ending in .disabled will not be executed (assuming 'path.config: \"/etc/logstash/conf.d/*.conf\"')."),Object(o.b)("li",{parentName:"ul"},"If you are not running a standard Netsage pipeline and actions in a particular .conf file are not needed in your particular case, they or the whole .conf file can be removed, but check carefully for downstream effects."),Object(o.b)("li",{parentName:"ul"},"MaxMind, CAIDA, and Science Registry database files required by the geoip and aggregate filters are downloaded from scienceregistry.netsage.global via cron jobs on a weekly or daily basis. (MaxMind data can change weekly, CAIDA quarterly, Science Registry information randomly.) ",Object(o.b)("strong",{parentName:"li"},"NOTE that new versions won't be used in the pipeline until logstash is restarted.")," There is a cron file to do this also. Similarly for other support files, eg, those used in 90-additional-fields.conf."),Object(o.b)("li",{parentName:"ul"},'"Member organization" lists that we have stored are available to download from sciencregistry.grnoc.iu.edu. See the cron files provided. These will not be updated often. You will need to provide lists for other networks yourself or ask us. (See Docker Advanced Options.)'))),Object(o.b)("h2",{id:"logstash-sequence"},"Logstash Sequence"),Object(o.b)("p",null,"The main things done in each conf file are as follows. (Please double check the comments in the files themselves, as well, in case this documentation fails to keep up with changes.)"),Object(o.b)("h3",{id:"01-input-rabbitconf"},"01-input-rabbit.conf"),Object(o.b)("p",null,'Reads flows from a rabbitmq queue. (The ".disabled" extention can be removed from other 01-input configs available in conf.d/ to get flows from other sources, probably for testing.)'),Object(o.b)("h3",{id:"05-translate-pmacctconf"},"05-translate-pmacct.conf"),Object(o.b)("p",null,"Renames fields provided by pmacct processes to match what the pipeline uses (from before we used pmacct). "),Object(o.b)("h3",{id:"10-preliminariesconf"},"10-preliminaries.conf"),Object(o.b)("p",null,"Drops flows to or from private IP addresses;\nconverts any timestamps in milliseconds to seconds;\ndrops strange events with timestamps more than a year in the past or (10 sec) in the future;\nsets duration and rates to 0 if duration is <= 0.002 sec (because tiny durations/few samples lead to inaccurate rates)"),Object(o.b)("h3",{id:"15-sensor-specific-changesconf"},"15-sensor-specific-changes.conf"),Object(o.b)("p",null,"Makes any changes to fields needed for specific sensors. This config currently provides 1) the ability to drop all flows that do not use interfaces (ifindexes) in a specfied list; lists can be sensor-specific, 2) the ability to change the sensor name for flows from a specified sensor which use a certain interface, 3) the ability to apply a sampling rate correction manually for named sensors, and 4) the ability to add subnet filtering for flows from specified sensors. "),Object(o.b)("p",null,"You may edit the file in a bare-metal installation and specify everything explicitly (upgrades will not overwrite this config) or you may use the environment file specified in the systemd unit file. For Docker installations, use the .env file to specifiy the parameters. By default, this config will do nothing since the flags will be set to False."),Object(o.b)("h3",{id:"20-add_idconf"},"20-add_id.conf"),Object(o.b)("p",null,"Adds a unique id (evenutally called meta.id) which is a hash of the 5-tuple of the flow (src and dst ips and ports, and protocol) plus the sensor name. "),Object(o.b)("h3",{id:"40-aggregationconf"},"40-aggregation.conf"),Object(o.b)("p",null,"Stitches incoming flows into longer flows. The inactive timeout is 6 minutes, by default. So, if the time from the start of the current flow to the start time of the last matching flow is over 6 minutes, declare the previous aggregated flow ended and start a new one with the current incoming flow. The default active timeout is 1 hour, meaning any flows over 1 hour in length will be split up into 1 hour chunks. This may require the start time to be adjusted, to cut off previous whole hours."),Object(o.b)("p",null,"For sflow, aggregation uses the 5-tuple plus sensor name.\nFor netflow, aggregation uses the 5-tuple plus sensor name plus start time. This means that when there's a timeout at the router (default inactive timeout is usually 15 sec), the flows will stay separate. (In certain grafana dashboards, they will be added together.) Start times of incoming flows are adjusted. See comments in file."),Object(o.b)("p",null,"Notes"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},'When logstash shuts down, any flows "in the aggregator" will be written out to aggregate_maps_path (default: /tmp/logstash-aggregation-maps). The file is then read back in when logstash is restarted so aggregation can continue. '),Object(o.b)("li",{parentName:"ul"},"Your logstash pipeline can have only 1 worker or aggregation is not going to work! This is set in the logstash config file."),Object(o.b)("li",{parentName:"ul"},"Tstat flows come in already complete, so no aggregation is done on those flows.")),Object(o.b)("h3",{id:"41-thresholdsconf"},"41-thresholds.conf"),Object(o.b)("p",null,"Drops flows that are too small - under 10 MB, by default.\nFor flows with small durations, sets rates to 0 because sampling makes them too inaccurate."),Object(o.b)("h3",{id:"45-geoip-taggingconf"},"45-geoip-tagging.conf"),Object(o.b)("p",null,'Queries the MaxMind GeoLite2-City database by IP to get src and dst Countries, Continents, Latitudes, and Longitudes;\nif the destination IP is in the multicast range, sets the destination Organization, Country, and Continent to "Multicast".'),Object(o.b)("p",null,Object(o.b)("em",{parentName:"p"},"This product uses GeoLite2 data created by MaxMind, available from ",Object(o.b)("a",{parentName:"em",href:"http://www.maxmind.com"},"www.maxmind.com"),".")),Object(o.b)("h3",{id:"50-asnconf"},"50-asn.conf"),Object(o.b)("p",null,"Normally with sflow and netflow, flows come in with source and destination ASNs.  If there is no ASN in the input event; or the input ASN is 0, 4294967295, or 23456, or it is a private ASN, tries to get an ASN by IP from the MaxMind ASN database.\nSets ASN to -1 if it is unavailable for any reason."),Object(o.b)("h3",{id:"53-caida-orgconf"},"53-caida-org.conf"),Object(o.b)("p",null,"Uses the current source and destination ASNs to get organization names from the prepared CAIDA ASN-to-Organization lookup file."),Object(o.b)("p",null,Object(o.b)("em",{parentName:"p"},"This product uses a lookup table constructed from the CAIDA AS Organizations Dataset - see ",Object(o.b)("a",{parentName:"em",href:"http://www.caida.org/data/as-organizations"},"www.caida.org"),".")," "),Object(o.b)("h3",{id:"55-member-orgsconf"},"55-member-orgs.conf"),Object(o.b)("p",null,"Searches any provided lookup tables by IP to obtain member or customer organization names and overwrite the Organization determined previously.\nThis allows entities which don't own their own ASs to be listed as the src or dst Organization."),Object(o.b)("p",null,"Note: These lookup tables are not stored in github, but an example is provided to show the layout and tables we have can be downloaded via a cron job."),Object(o.b)("h3",{id:"60-scireg-tagging-fakegeoipconf"},"60-scireg-tagging-fakegeoip.conf"),Object(o.b)("p",null,"Uses a fake geoip database containing ",Object(o.b)("a",{parentName:"p",href:"http://scienceregistry.grnoc.iu.edu"},"Science Registry")," information to tag the flows with source and destination science disciplines and roles, organizations and locations, etc;\nremoves Registry fields we don't need to save to elasticsearch."),Object(o.b)("p",null,"Notes: "),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"The ",Object(o.b)("a",{parentName:"li",href:"https://scienceregistry.netsage.global/rdb/"},"Science Registry"),' stores human-curated information about various "resources". Resources are sources and destinations of flows.'),Object(o.b)("li",{parentName:"ul"},'The Science Registry "fake geoip database" is updated weekly and can be downloaded via wget in a cron job (provided in the installation).')),Object(o.b)("h3",{id:"70-deidentifyconf"},"70-deidentify.conf"),Object(o.b)("p",null,"Replaces the last octet of IPv4 addresses and the last 4 hextets of IPv6 addresses with x's in order to deidentify them."),Object(o.b)("p",null,"Deidentfication can be skipped by using an option in the environment file."),Object(o.b)("h3",{id:"80-privatizeorgconf"},"80-privatize.org.conf"),Object(o.b)("p",null,'Removes information about Australian organizations (or, with modification, any country that has privacy rules that require us not to identify organizations).\nIf the ASN is one of those listed, completely replaces the IP with x\'s, sets the location to central Autralia, sets all organizations to "AARNet", removes all Projects.'),Object(o.b)("h3",{id:"88-preferred-location-orgconf"},"88-preferred-location-org.conf"),Object(o.b)("p",null,"Copies Science Registry organization and location values, if they exist, to the meta.preferred_organization and meta.preferred_location fields. If there are no Science Registry values, the organizations and locations from the CAIDA and MaxMind lookups, respectively, are saved to those fields."),Object(o.b)("h3",{id:"90-additional-fieldsconf"},"90-additional-fields.conf"),Object(o.b)("p",null,"Sets additional quick and easy fields.  Supporting mapping or ruby files are used - see support/ and ruby/ in conf.d/. Currently we have (for Netsage's use):"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"sensor_group  = TACC, NEAAR, I-Light, etc.  (based on matching sensor names to regexes)"),Object(o.b)("li",{parentName:"ul"},"sensor_type   = Circuit, Archive, Exchange Point, Regional Network, Facility Edge, Campus  (based on matching sensor names to regexes)"),Object(o.b)("li",{parentName:"ul"},"country_scope = Domestic, International, or Mixed  (based on src and dst countries and possibly continents, where Domestic = US, Puerto Rico, or Guam)"),Object(o.b)("li",{parentName:"ul"},"is_network_testing = yes, no  (yes if discipline from the science registry is 'CS.Network Testing and Monitoring' or if port = 5001, 5101, or 5201)"),Object(o.b)("li",{parentName:"ul"},"es_doc_id = hash of meta.id and the start time of the flow. If this id is used as the document id in elasticsearch, flows that are mistakenly input more than once will update existing documents rather than be added as duplicates. (NOTE: due to how netflow works, use es_doc_id as the ES document id only for sflow!) This id may or may not be used for the document id in Elasticsearch. It may be used for other purposes in grafana dashboards, as well.")),Object(o.b)("h3",{id:"95-cleanupconf"},"95-cleanup.conf"),Object(o.b)("p",null,"Does small miscellaneous tasks at the end like rename, remove, or convert fields"),Object(o.b)("h3",{id:"98-post-processconf"},"98-post-process.conf"),Object(o.b)("p",null,"Adds @exit_time, @processing_time, and @pipeline_ver (these are mainly for developers)"),Object(o.b)("h3",{id:"99-output-rabbitconf"},"99-output-rabbit.conf"),Object(o.b)("p",null,'Sends results to a final RabbitMQ queue. (".disabled" can be removed from other output configs to send flows to other places)'),Object(o.b)("h3",{id:"final-stage"},"Final Stage"),Object(o.b)("p",null,"In the GlobalNOC-Netsage case, the output filter writes the flows to a network-specific RabbitMQ queue at Indiana University and the last stage is a separate logstash pipeline. The latter reads flows from the final queue using a rabbitmq input filter and sends it into elasticsearch using an elasticsearch output filter with a mapping template which sets data types for the fields. "),Object(o.b)("h2",{id:"field-names"},"Field names"),Object(o.b)("p",null,"The fields used/created in Logstash (and saved to Elasticsearch) are listed in the ",Object(o.b)("a",{parentName:"p",href:"elastic"},"Elasticsearch doc"),"."))}d.isMDXComponent=!0},209:function(e,t,n){"use strict";n.d(t,"a",(function(){return f})),n.d(t,"b",(function(){return h}));var a=n(0),i=n.n(a);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function s(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?s(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):s(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var c=i.a.createContext({}),d=function(e){var t=i.a.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},f=function(e){var t=d(e.components);return i.a.createElement(c.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return i.a.createElement(i.a.Fragment,{},t)}},p=i.a.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),f=d(n),p=a,h=f["".concat(s,".").concat(p)]||f[p]||u[p]||o;return n?i.a.createElement(h,r(r({ref:t},c),{},{components:n})):i.a.createElement(h,r({ref:t},c))}));function h(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,s=new Array(o);s[0]=p;var r={};for(var l in t)hasOwnProperty.call(t,l)&&(r[l]=t[l]);r.originalType=e,r.mdxType="string"==typeof e?e:a,s[1]=r;for(var c=2;c<o;c++)s[c]=n[c];return i.a.createElement.apply(null,s)}return i.a.createElement.apply(null,n)}p.displayName="MDXCreateElement"}}]);